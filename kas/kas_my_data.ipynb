{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef91fb0-becf-4fa7-a349-a0866921855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of modules failed: Traceback (most recent call last):\n",
      "  File \"/home/w/IML/.venv/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/w/IML/.venv/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/w/IML/kas/modules.py\", line 5, in <module>\n",
      "    from .attention import DotAttender, MultiheadAttender\n",
      "ImportError: attempted relative import with no known parent package\n",
      "]\n",
      "[autoreload of informed_nps failed: Traceback (most recent call last):\n",
      "  File \"/home/w/IML/.venv/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/w/IML/.venv/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/w/IML/kas/informed_nps.py\", line 4, in <module>\n",
      "    from .modules import *\n",
      "ImportError: attempted relative import with no known parent package\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d424606a-4351-43e2-b28b-757d665398d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INP(\n",
      "  (xy_encoder): XYEncoder(\n",
      "    (pairer): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=129, out_features=128, bias=True)\n",
      "        (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (activation): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (latent_encoder): ModulatedLatentEncoder(\n",
      "    (encoder): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
      "        (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "      (activation): GELU(approximate='none')\n",
      "    )\n",
      "    (knowledge_encoder): ModulatingKnowledgeEncoder(\n",
      "      (text_encoder): RoBERTa(\n",
      "        (llm): RobertaModel(\n",
      "          (embeddings): RobertaEmbeddings(\n",
      "            (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "            (token_type_embeddings): Embedding(1, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): RobertaEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0-11): 12 x RobertaLayer(\n",
      "                (attention): RobertaAttention(\n",
      "                  (self): RobertaSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): RobertaSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): RobertaIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                  (intermediate_act_fn): GELUActivation()\n",
      "                )\n",
      "                (output): RobertaOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): RobertaPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (knowledge_extractor): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=896, out_features=256, bias=True)\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "      )\n",
      "      (activation): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      "  (x_encoder): XEncoder(\n",
      "    (mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (activation): GELU(approximate='none')\n",
      "    )\n",
      "  )\n",
      ")\n",
      "1105026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.836896489503019e+21\n",
      "tensor(5.8369e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5176.4438, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAESCAYAAACCU7B8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABYiklEQVR4nO2deZxcVZn3f/fWvld1V3X13unO0tkXsgdBkEgQFIGgwKACAo5O4FWDjCIjqOM7AeFVRxREwKjjQBAUFJHNQBIJAUISyL500kmv1Xvt+73n/eNW3a7qJem1lq7n+/nUp7rPPVV16nbX/dXznGfhGGMMBEEQBFEg8NleAEEQBEFkEhI+giAIoqAg4SMIgiAKChI+giAIoqAg4SMIgiAKChI+giAIoqAg4SMIgiAKCmW2FzBeRFFEW1sbTCYTOI7L9nIIgiCILMAYg8/nQ3l5OXj+7DZd3gtfW1sbqqqqsr0MgiAIIgdobm5GZWXlWefkvfCZTCYA0ps1m81ZXg1BEASRDbxeL6qqqmRNOBt5L3xJ96bZbCbhIwiCKHBGsuVFwS0EQRBEQUHCRxAEQRQUJHwEQRBEQUHCRxAEQRQUJHwEQRBEQUHCRxAEQRQUJHwEQRBEQUHCRxAEQWQNxhgEkWX0NfM+gZ0gCILIHwSRISqIiAkiooKIqMCgVnCwGzQZWwMJH0EQBDEpMMYQE1hC4KTb0NZdZhsMkPARBEEQE0JcFBGNsxRrTsz2koaEhI8gCIIYNSJjiMaTLkvJqhNZZvfqxgoJH0EQBHFOZCsuLt3HMxyQMpGQ8BEEQRBpiCzhroyLiCQsOpYn1txIIOEjCIIocETGEIn3C10sg3tzosgy+noACR9BEETBkSZ0cRExMTPCIzKGuCjl7cUFhrgoQmSAXq3IyOsnIeEjCIKY4jDGEBUYInFBErwMWFhpIpe4iTmyL0jCRxAEMQWJi5I1F46JiMQFTKbk5LLIDQUJH0EQxBQgmV4QjosIx4VJKwMmsnSBy3WRGwoSPoIgiDwlLkoWXTguIBoXJ9yqmwoiNxQkfARBEHmCtFfXL3YTmUs3VUVuKEj4CIIgchhBlIJSwgk35kTk0zGWLnBTWeSGgoSPIAgix5CsuomJwCx0kRsKEj6CIIgsk8yrC8cky26sNS9TRU5IuSfSIeEjCILIAnGhPwIzEh+9VUciN3ZI+AiCIDJA0qqLjCHdIDXwhERu/JDwEQRBTBIxoV/oRmrVCQPELc5oT26iIeEjCIKYIOS9uoTQnc0qY4xBSKl4khS7KdQEIWch4SMIghgjyby6pAtzuAjMIV2VjGFS64gRw0LCRxAEMQpiiaCUyBDVUhhjEBlSBE6y+shTmVuQ8BEEQZyFuNjf1SCSkmrA2GALTiBXZV5AwkcQBJHCUNGX+dZ9gDg7fKZe6IEHHgDHcfjGN74hj4XDYWzYsAHFxcUwGo1Yv349Ojo6MrUkgiAIAJL70heJozsQQasnBJc3jC5/BH3BaOIWgy8cRzAquTdJ9PKbjAjf7t278fjjj2PhwoVp49/85jfx0ksv4bnnnsP27dvR1taGa665JhNLIgiigGFMcl/2BqNocgdxpi+IVrckeH3BGHyROEIxATGB9uemIpPu6vT7/bjxxhvxxBNP4Ec/+pE87vF48NRTT+Hpp5/GJz7xCQDA5s2bMWfOHLz77rtYtWrVZC+NIIgCQmQMvkgc/kgcgaiAmHD2dANi6jLpFt+GDRtwxRVXYO3atWnje/bsQSwWSxufPXs2qqursWvXrmGfLxKJwOv1pt0IgiAGwhhDMBpHhy+Mhm4/Drm8ONMbRE8ginBs8hq1ErnPpFp8W7Zswd69e7F79+5Bx1wuF9RqNaxWa9q40+mEy+Ua9jk3bdqEH/zgBxO9VIIg8pxkTl0wKsAbiSMYjSMmkLgRg5k04WtubsbXv/51vPHGG9BqtRP2vPfccw82btwo/+71elFVVTVhz08QRH4gCR1DNC7AHxUQiMbPWS2FIIBJFL49e/ags7MT5513njwmCAJ27NiBX/ziF3jttdcQjUbhdrvTrL6Ojg6UlpYO+7wajQYajWaylk0QRI7CGENMYIgketUFo3GE4wwxQaAAFGJUTJrwXXLJJThw4EDa2C233ILZs2fj29/+NqqqqqBSqbB161asX78eAHDs2DE0NTVh9erVk7UsgiDyBMYYYmIyp05IKwsWE0RKFCfGzKQJn8lkwvz589PGDAYDiouL5fFbb70VGzduRFFREcxmM+68806sXr2aIjoJokCJpdS9jAgiBEFEVBQRjTPExtmJnCCSZLVyy09/+lPwPI/169cjEolg3bp1ePTRR7O5JIIgMogsdIIoJYYnyn5FE7/HyYc55WHIfBUcjrH8dhh4vV5YLBZ4PB6YzeZsL4cgiLMwlNBJNS+RcGEKIMNu6sEg1TAVRQYRgCACDCJEBjAGGNQKLK6wjus1RqMFVKuTIIhJIRmMkmzbExX6CzyLKcdov25qwCBVuRFFBobB4pZLkPARBDEhCKK0D5cUupiQ3rIn6cKMCSLl1+Up+SRuZ4OEjyCIUZNqzSVvA/Pnkm17ogIjF2YeIaa4JSVxY4l9uKnTN5eEjyCIcxKXBa7fahsKUZRSEJJiOGWulFMMMWG5sRRxE1nhFOQm4SMIIo1Ul2RS7M4WAxcXGWKJPTyKwswdxKSVlhA0SdgKR9zOBgkfQRQwybJfsbO4LId/DFVNyTZpbkkGCCRuI4KEjyAKiKTAxc7hshyIKDJKJM8iqdaaHFBCnuQxQ8JHEFOU0bosU0nm1sVGaAUS4yeZ6yYU6L5bJiHhI4gpQDyRShATRMQSP49WrCi3LjOkpgTQ3lt2IOEjiDwiWbg5JoiIJ0VKHLklN5A0waTcugklNXJSTOy/MRK4QfCxIPR9xwHBCFSvzMhrkvARRI6STAiPpYjTeKMm5dy6OENUFCDSdt24SUZPiixxn4cJ3ZlCGe6DofcQjL2HYeg9BEPvYei8jeCYCNReCNz0UmbWkZFXIQhiWOKiZL0lra94IhduosroyoEpgpR2QIwNSdjSa01SnM8wMAZ1oC1N4Iy9h6AJtA85PaZzQGV0Zmx5JHwEkQHEhKUlCZyY9vNkGAaxlNw6CkwZORRgMgZEATrfaRh6DqYJnSriHnJ6yFSDQNFcBIrmwl80D4HieVBbSsddpHo0kPARxASTum8WTezFCZPs90oGpiRfk9xs5ybVRUkCN0JEATrPSRh7D8LYczAhdkegiAcGT+WUCFlnSOJWNBeBonkIFM2GoB7cOUGdibWnQMJHEONgoMjFBCZ3IJhsqOjzyBHBIApJNyVLBJpke1U5jhiH3n0Cxt5DksD1HISh7wgU8dCgqYJSh4Btjixw/uK5CFpngSk0WVj4uSHhI4gRMjAvLpMiB6QHpsREKvo8HPJeHAPiiZ9J484BE6HznIKpax+MPQdg7DkIfd8RKITIoKmC0gB/0VwEiufBX7wA/uL5CJnrAF6RhYWPDRI+ghiCbItcEqnoc39xaLqCp9PvppTSBWg/c2QoYn6YOvfB1LUXpq59MHV/CGXUO2heXGVMWHDzZaELmabllcgNBQkfUfDkisgB/d0NUoNgCAkSubGjjLhh7vgA5o73YO54H8beQ1IKQQqCQgu/fSH89kXwF8+Hv2gewuZpAMdnZ9GTCAkfUVAM6iMXFyc98ORsa4mLSInyFCm4IoEUeJJwV4rkrhwtqlAXzB27YXG9B3Pn+zD0HRs0J2yshLdkKXyOJfA5zkPQVg/Gq7Kw2sxDwkdMaUTGEI2LaUKXrQuoICZz9RgEsubSSFpwFF05NtT+Vlg6dsPc8T4sHe9B520cNCdomQ6vcwW8zuXwOFcgaijPwkpzAxI+YkqRdFtG4yIio+g+MNEkXZaS2EkiR1GEEskIS4EBAqMk8FHDGLS+0wmR2w2z6z1oA63pU8AhYJstC53XuRwxnSNLC849SPiIvEYQGSJxERFBQDSeHStqkMtSFKkUWArJ5H2y5sYIE6F3n4C5433JfdnxPtShzvQpnAL+onnwlq6Ex7kCvpKliGus2VlvHkDCR+QFyVD+9NqV2QlCSYpbXJDEjoIs+mFgEMR0sSNGiSjA0HdE2p/r2A1z526oIn3pU3g1fPaF8DpXwutcAV/JEggqY5YWnH+Q8BE5RVLgUkUuPgHFmcfKQJclJYqnI8p7c5LbknRuDDAR+r5jsLjelW4d7w1KLRAUWvhKzoMnIXR++yKISm2WFpz/kPARWWNg94Gk2GUL6SJOUZZDkVrDktIJxglj0HlOwuJ6JyF270MV6U2bElcZ4S1ZCq9zJTylKxEomgemyHRhr6kLCR8x6aT2kEvWk5zI7gNjJTXKstBdlmJC2JJpAyzRIDXZNJUCc8ZBIhjF4noXlvZdsHS8B3WoK22KoNTBW7IMntLV8JSuhr94HsDT5XmyoDNLTChSseREC5wJ6iE3ETDGEGeQ3aaF1GE8KWos0VInVdSkn7O9wikGY9B6G2HulPLoLK53oQm60qYICg18jvMkoStbBX/xwoKz6EQmoC/Sha5QKzwxF1zRElxWe1lGXpuEjxgXIpOiKsPx7EVVDkVy7ylpzU3FvblU4WJMstT6fyZRyxhiHMbewzB1fpAIRvkA6nBP+hReDZ9jMTylq+ApXQ2fY3HOFnCeSAQxjp6IC12hVnSGWtEVbkVXqBVdoTZ0h9sRZzF57pLeJSR8RO4iMoZQTEAoJiCSI41Np1qpr4FWGhggsKTYUUpANuFjQZi6P5RFztS1D4p4MG2OFHW5SEoWL1sNn+M8iEpdllY8ucTECLpC7QlRa5OELSwJXW/YBRHDXyMUnBJ2bRnKDJVYWbYoY2sm4SNGRK6JXX9KQXJ/LtsrGjli0jobYj+NrLTcQxnugblzjyx0hp5D4Fk8bU5cbZaCUUqWwetcDn/xgill0YWFILpDbSlWmyRwneFWuCNdOFtBORWvgUNbDoeuAiW6Cji0iXtdBWwaB3hOAYNaQY1oidxAZAzhmIBQTHJlZovUBPGk6zJX9+eSCdoDXY9JscvVdRP9qEJdUg5dIrVA7zk5aE5EXwavc5ksdEHrrLwv5hyI+dCdsNSSoiZZb23wRnvP+litwiCLmSxyWul3i7oYHMdl6F2MDBI+Io1cETshpR1PLAfa8Qy5nyYiEfWYcEtmd4nEGFGFumFx7YLF9S7Mrveg954aNCdomZkQOqn8V8RQDuTYxfxcMMbgi7llV2RXmgXXikB8cFuiVAxKc4q4VaT9bFRZck7czgYJHyG7McNZFLvUrgmxDJf8Gj7qEbSfNhUR4zB37YW1dQdsrTtg7D2YdpiBQ6BoDrzOFfCUroK3ZDniWluWFjs6RCbCE+1JBJCkW21doVaEheBZH29RF8OhrYBDl261OXTl0CtNGXoXkw8JX4EiiAzhePb37GIiQzQm1dqcDDdgmusxkXidFDRyPRYO6kAbbK3/hLVtO6xtO6GM+dKO+21z4ClbnSgBtjyn61yKTEBvuFO21GRxSwhcTIwO+1gOHGyaElnU7Lpyed/NriuDVqHP4DvJHiR8BYQg9geoRLNZIUVkiAgiIvHxJY33ux8TFpssbJR0XehwQgTmjt2wte6AtW0HDO7jacdjGhvc5R9DX8XH4S6/IOc6F8TFGHrCrhRRa5OFrjvcDmFAcE0qPHgUa0sTllqq1VYBu7YUKn7qBN2MFRK+KU6uiB1jDFFByvkbaVkyWdgGuCCpwj8xFBp/K2yt22Bt3Q5r+ztpKQaM4+GzL4a74kL0lX8c/uL5AK/I4mqBqBBBdzh9n60z1IrucBt6wh1gZ0kDUHIqyVobYLWV6CpQpHFCQVVfzgqdnSlILqUexIT+tkFDRX9InbbTXZEULEKMBE6Iwtz5AWyt22Fr2Qa950Ta8ajOgb7yC9FXeRE8ZednxX0Zigfk/bXU/LauUCvc0e6zPlbNa9NSAJIRkyW6Clg1dvBcdoU7nyHhmyIwxhCOi4kgFSGrotHvyhTkFjViikuSrDZirKgD7bLQWdt3QhEPyMcYx8PrOA/uio+jr+IiBIrmZiTyMhDzDqpKknRR+mJ9Z32sTmEYJG7JaEmzqiivIiXzCRK+PCcSFxBMpB9ks+hzUniDUcmlSk1HiYmAE2Mwde6BrXUbbC3bBu3VRbV29FV8HH2VF8Fd9jEIGsukrCMihNAZakFHqAWdwWbpPnE7VxqASWWVw/4duvK0VACD0kzilgVI+PKQaMKyC8UECBkQu9QIyNRKI8m2QuG4lApBGkeMm2TLnvZ3YG1/BxbXO1DG/P2HOR4++5KE2H0cgaJ5E5Y4LjIRPeF2tAfPJESuGZ1B6f5cbkmL2j6oKomUyF0OnZIaxOYaJHx5QkwQE5adMCgSMmnpyaMJgUpNtk4Gisi3lCJD0sPT99VS5w+EgUEQGKJ5ViqMyE00/lZYEiJnbd8Fdagz7XhUWwx3Yq/OXX7BuPfqGGPwRHvQFmhEW7ARbYFGtAZOoT14BlExPOzjDEoznPoqlOgq4dT13zt05dAopmYdzqkKCd8kkdzPAgaITkqoPUsVG5YuRAxANC4gHBcRjouIC0mLKsX6yrCJJSaSzGMCWXfE2FGGe2Bt3yVVS2l/BzrfmbTjgkIDX8kyuMvWwFO2Bv7iBWO26uJiDM3+E2jyn0gTuuHck0pOhVJ9NZz6ajh1lSjRVSXuK2FQmce0BiL3mFTh27RpE/785z/j6NGj0Ol0WLNmDR588EHU19fLc8LhMO666y5s2bIFkUgE69atw6OPPgqn0zmZS5swBLE/RD+W6Aow1ty0VGGJ5Uj3b7LuiPGiiPpg7ng/4brcBUPf0bTjjFPAZ18ET9kauMvWwOdYMuYCz6F4AI3ew2jw7keD5wAafUcQEyOD5nHg4dRVotxQK9300r1DVw4FR/bAVGdS/8Lbt2/Hhg0bsHz5csTjcXz3u9/FpZdeisOHD8NgMAAAvvnNb+Lll1/Gc889B4vFgjvuuAPXXHMNdu7cOZlLGzMiY4jGRbkH3Xjb3yQLL0cFqdNArkDWHTFWOCECc+de2X1p6t4PjqWXwktWSvGUrYHXuQKCamz7YJ5IDxq8B9DgOYAG7360+E8Oyn8zqiyYZpqDCkMtyvV1qDDUwqmvokTuAoZjGQwF7OrqQklJCbZv344LL7wQHo8HDocDTz/9NK699loAwNGjRzFnzhzs2rULq1atOudzer1eWCwWeDwemM0T54pgjEFIJE8LjCEuMkTiE5MXFxdERAUREYFBzAWzLgGD1M8uRtYdMRrEOIw9h2Bx7YS1/R2YOvdAIaRbWSFTjWzReUpXIa4tHvXLMMbQEWrGSc8BnPDux0nPAXSF2wbNs2vLMcO8ADMs0s2pq6bIyRxnItoSjUYLMmrTezweAEBRUREAYM+ePYjFYli7dq08Z/bs2aiurh5W+CKRCCKR/g+V13v2UOKREowJCEbjEERJ8Cb6+0AsIXbReG64MFORrDupEwJBnBPGoHcfl/foLK530yIvASCqK0mInGTVRYwVo34ZQYyjyX8CJxMW3UnvAfhi7rQ5HDhUGqZjumUBZlgWYrp5Pmya3Co/RuQeGRM+URTxjW98A+effz7mz58PAHC5XFCr1bBarWlznU4nXC7XkM+zadMm/OAHP5jw9cUS7suJJLn/F4kLOSd2ZN0Ro0Hja5bTCyztu6AOp4f3x9VmeEpXwV0qBaSELNNHnTweFoLS/pznABq8B9DoPTwoylLJqVBrnitbdHXmeZQuQIyajAnfhg0bcPDgQbz99tvjep577rkHGzdulH/3er2oqqoa7/ImjP6alAJiOWhBiSzR+icH10bkDqpgJyyuXbC6dsHSvgtaf3PacUGhhde5HJ6EVecvmjfq2pfeaK8scg2e/WjxN0AcsD+nV5oww7xAsujMC1BtmgUVrx73+yMKm4wI3x133IG//e1v2LFjByorK+Xx0tJSRKNRuN3uNKuvo6MDpaWlQz6XRqOBRpN7m9JCYg8wHM+97uAMiUCVDPe5I/IHZcQNs+tdOc1A72lIOy5ySvgdixLuy/PhcywaVeRlcn/ulPcQGjz70eA9gM5Qy6B5RRqntDdnllyXpfoa8Hne2ZzIPSZV+BhjuPPOO/HCCy9g27ZtqK2tTTu+dOlSqFQqbN26FevXrwcAHDt2DE1NTVi9evVkLm3CEESGYExANMvFoIdCYGIiMjPHlJjIOoqYH+aO3bAkhM7QexhcSvyu1Ix1nuS+LFsDr3M5RJVhRM8dEUJoC5xGa+AkWgOn0BI4idbASQTj6fuAHDiUG2ox3bwAMy0LMd28AEXakgl9nwQxFJMqfBs2bMDTTz+Nv/zlLzCZTPK+ncVigU6ng8Viwa233oqNGzeiqKgIZrMZd955J1avXj2iiM5sIiYEL9vdDwYiW3c5kgdI5AZ8PAxT1x5Z6IZKMQhaZsJdthqe0tXwlq48Z4WUZImvlsApWeRaA6fQFWpNqQvUj4pXo9o4CzMsCzHDvAB15vkwqKZOV29i7DDGEIoK0Kkz03FiUoXvscceAwBcdNFFaeObN2/GzTffDAD46U9/Cp7nsX79+rQE9lxFZAzhWO65NAVRisocb14hMTXghCiMPfthaZf26Uyde8EP6MwdMtUkoi5Xw1O66qzNWAMxryxsbYFGtAROoi1wCpFhSnyZVTZUGKajwliHSsN0VBjqUK6vpT5xBYooMvQFo+j2R9Hti6DbH0m5j6LHH8Hq6cX47S0rMrKejObxTQYTlcfnCcXgjw7f1Ti17U+unDGy7ggZUYCx91AixWAXzJ27oYiH0qZE9KUpQrd6yBSDmBhFR7Ap4aI8hbaE2A1XpFnJqVBuqEWFoQ4VhumoNNSh3FAHs9o2KW+TyE3igogef3SQoHUlfu8NRM9Z0WpGiRH/2PjxMa8hZ/P48hHGpJSEUCx3UhKS1V7Iuitg0nLpdiVy6XxpU2KaItmac5euRthcK6cYMMbQG3bJVlxrQuRcoWaIA1ygSYo0zoTAJaw443SU6CqoxFcBEIkJ6PZH0eUL91ttKZabOxg7Z4UnngOKjRrYjWrYTRrYjRr5vrpIh0/UZ25/l/5jh4ExqZlqKCbmRHUVMVE9JirklouVyBCMQes7Lbsuza53oQ73pE2Jq4zwlK6SrbqgdRbA8QjGfWgNNKK1/S9oky25RoSFwJAvpVcaE6W9+m/lhlrolCMLbiHyj2hclEWsa4ibNxQ753OoFFy/oMmiJomcw6SBTa8Gzw+d22lQK6BRZq6jPAnfAHJJ8MREgWhKMi9AGIMm0CalGCSsOk2wPW2KoNTBW7IcntJVcJUsQYvBDnesD32RLnS4t6O19bdoDZxCX6RzyJdQcEqU6qtTxK0OFfo62DQOKvE1xYgJInr8/ULW7Yug09cvdO7guYVNq1LAkRCxwVabGmadKm/+b0j4EkguTQHBLAte0rKLk9gVFKpgJ4w9B2Ds2Q9j9wEYew5AHe4BA+DmeTQqFXAZTDhjrUGLqQztGjM6eQF90R64vS8h3LflrM8vuSlrUZ5wU5YbauHUVUHJqzLzBolJJS6I6A1E0emV3I8DLTZ3IHpOV6RGycvC5jBJglZi0soWm0GjmDRhy7RekvAlCEQF+CND721MJiIYRIEhnhA8cmNOfZThHhh7DkLXtR/R3r0IeI6hL+7BCaUCHQolOpQKdFgV6FCWo1OpRDTtouAFIl5gcKcd6BQG2DQOWDUO2LXlCUtOarejV1LaQD4jiAy9gYSQeRNWW4rA9Qai57x2qJU87EYNSsySpSaLnFkDh1EDo1Y56RYbxwEKjgPPceA5gOcBnuNgUGdWikj4EmRKb0Qm9euLiwwiYzkTMENMPGEhCLe3AYHu3fC6D6EveBrdkR50I4oOpQLdCgUEJQcUqwGcvbCySWWTRE1th1XjkH9OCp1VY4dWoc/MGyMmHFFk6A1EZUHr9CbckIl9tx5/5JzXiuQem8OYEDNTisCZtTBnQNiSDCdwHHLDFUrCN8kkXZdC4kY6N3UIC0H0hjvQE3ahJ+JCb6AZbt9x9Iba0Bn3wMsN8CBwALQcgP5SXzw42JQWWLSlsGqdkoglBE0SNwcsmmKqT5nniIyhLxDtDx7xS5ZbUtx6/OcO91fyieCRAeLmSOyzWfQq8Bn2GfIcEuKWmwI3HCR8kwB1PpgaRIQQesId6Im40BNulwROvrXDHz9LS6zE594sCCgTFShRmlGkLYPVPBN62wJYDDWwqu0wq23gucxFsxGTg8gYPMFYWvBI6h5bjz9yzvQjBc+lRUEO3GOzZkHYkiQFTsFz4AHwPAeOQ84L3HCQ8E0gIhhicepani8wxtAX6YIr1ITOUEu/qEVc6A27BvV+GwqTIKIiHkd5PI6KeBxO3gCbvhpm61wYildALFmGuJaSufMdxhi8odigoJGkwHX7I+esiZvMY0sNHkkNJjlbuH8mUfD9VpwiTyy40ULCNwFQQnnuExMjaAucRkvgJFr8J9ESaEBr4BSCcd9ZH2dgQGUshopYLCFugixydqUVXNEC+B3z4bcvhL94QVrZr+hZnpfIPeKClMvW7g7D5ZFuXSnCdq5C9BwHFBnUgyIjpZ+1KDKoocgBYUvCQbIyeY6DgpOsuGxZlJmGhG+MiAl3JiWU5x6eaA9a/A0pIncSHcGmQb3eAEABBUqVZlQJQHU4gJpAFypiUdmKMye+zES1xfAXL0KgWBI4r30BuvXOTL81YgIQRQaXN4wz3QE09QTR1BuURe5s+2wcAFtC2CQ3ZLrVVmRQQ6nIzRZKHKT9NwXHSyKn4MBPMStuNJDwjQIGKUCFrLvcIBDzoiPUjM5Qi1RbMiFyvljfkPMNShNqNGWYISoxJ+DBot5TqPd1YGDYSExjhd++DJ7iBWgtXgB/8XxEDeWZTzYixk04Jkji1hPAmZ4gzvQE0dIbHLarilrJo9SsRalVC6dZixJz/z5bsVENVY4K20AUqSJXQJbcSCHhGwFk3WWPqBBGZ6hVFjj5PtiMwDDBJRw4lOgqUaWvRR10mBPyYUHfGdS1HIAqdihtrsir4C1eAF/JUvjsi+AvXoCIsZJELs9gTEoHONMTRFNPEGd6JGuuwxMecr9dreRRVaRDdZEB1cV6VNh0KLVoYTOo804kJJHj+oNP8mz92YCE7ywwMETjkuARk4cgxtEdcaEz1ILOYDM6Qi3oDEn3w5XbSmJV2+HUVaFUX4NqTSnmRMKY29eMks59MPRsAc/SO27EVUZ4S5bCV7IM3pLl8NsXQlRqJ/PtERNMXBDR6g5JApdwV57pCcIfGbq7ilWvQk2xJHA1xXrUFBtQatHmRCDJaEkGmyhI5MYFCd8wxAQRkThFZ04UIhPhjnQlLDbJgusKtaAj1ILucPuwHQEAqWiyU1eFEl0VnLpKlOir4NRWoiouoKTnIMydH8DU+DL0npODHhvRl8JbsgxepyR0QessgKf0gXwhEhNwpieIU11+nE6IXEtfaMi9OJ4Dym061BQZUGPXo7pYj+piAyy6/CzLxicsORK5iYeEbwCCKCIsiBDJyBsTgZgP7cFG2WrrDLWiI9iMrnArYuLwcY4qXoMSXQVKdJUJkZPunfpKGJQWcEyAoe8IzB0fwNz4HMwdH0AdHtwjLmiZKYuc17kMEUMFuS3zhLggork3hFNd/sQtgJbe4JAVS/RqRcKCM8j3FTYd1Mr82IMbCIlcZiHhSyCKDKGYQEErI0RkAjpDrYmgEimCsjVwCr2RjmEfo+CUsGvLZGFL3pz6SljUdvBc/0WLj4dg6voQptP/A3PHbpi79kERT2+jI/Jq+O0LJIuuZBl8jvMoZy5PEEWGNncIJ7v8aOwK4FSXH009wSFz4ax6FeocRkyz61FjN6CmWA+7UZM3nQAGkkwjkG5TM08u1yHhSxCKk+gNRzDuQ6v/lJQekBC4tkAjomJ4yPlFGidK9dX9wpa4L9I6h29aKsZhcb0HW+s2mDt2w9BzcIj9ORO8JUvhdS6Ht2QZ/PaFYArN0M9H5AyMMXT5IjjZ6cfJrgBOdUpuy6EiKw0aBWodRkx3GFDnMKLWYUCRQZ23IgdILlgFT9ZcLkHCR8iITEBXqC0hbv05cMNZcSpe09+N21CHSuMMVIyiEwAnRGBt34niM6+hqPkfUEXS0xD69+ckoQva6gEuP11ZhYQnFMOpTj9OdkruypNdfvjDgwNPNEoetQ5DmtCVmPPXkkui4AElz8uCR9Zc7kHCV6CE4gFJ3BIC1xo4idZzWHFJkas0zkClYTocuvJR15nkYwHYWrejuOk12FregjLml4/FNDb0Vn4CnrLzaX8uTwjHBNlVeTIhdt3+wXu5Sp5DdbEedQ4j6koMmO4wotyqy8vIylQoXy4/IeErACJCCM3+BpzxH0OT7xhO+46iI9Q85FwVr0a5vhaVxumoNMxI9HSbDoNq7P3clBE3bC1vovjMa7C27YBC6G8mF9E50VOzDr3V6+BxLgd4+pfMVQKRONrcISnKstOPk11+tPaFBuW2cgDKrDpML5GsuOklRlQX6/Mm+Xs4SOSmDnSVmWLExCha/CdlkTvjP4a2wGmwIcp12dQOVBqno8IwA5WGOlQap6NEVzkh3QJUwU4UN7+BojOvweJ6N22/LmSqQU/NOvRUXwa/fSG5L3MIkTF0+6R6lW3uENrcIbS7Q2hzh+EJxYZ8TJFBjeklRlnoau0G6DX5fWkhkZva5Pd/Z4EjiHG0BRtx2tcvcq2BUxDY4P0Us7oI04yzUWOajRpTPaqNs2BWT2wEpMbXjOKm11Dc9BpMnXvBpWRBBmyz0VO9Dj016xC01pMLM8uEYwJcnoS49SUFLox2T+isXQZsBjUqbDpMd/QLnc2Q370Ck01T5UhL+t+c8pDw5RF9kU40eo+g0XcYjd7DOOM/NmRunFFlQY1RErgaUz1qjPWwauwTvyDGoPM0oPiMJHbG3vRyYF7HEvRWr0NP9aUIm6dN/OsTwyJ1GogO6AsXllvp9AWHtt4AaT+u1KpFuVWHMosO5VYtym3Szzp1/if/J4VOyXNQFHix5kKFhC9HiQphnPEfR6P3sCx07ujghG290ohqY7/A1ZjqUaRxTmpknCLqhePUi3AefxbGviPyOOMU8DhXSHt2VZciaiidtDUUOnFBRG8gOmzj075A9JxVh0xapSRu1oS4WXUot+rgMGnyPugklWTenJKndAJCgoQvR+gOt6PBc0AWuhZ/w6A2Ojx4VBino9Y0F3Xmuag1zUWJrjIz4d+MwdS1D87jz8B++mUoBCn6U+TVcJd/DD3V69BbdQni2qLJX0sBIIgsIWzhIYWtNxA9Z8F0tZKH3Zje7FRuqWPWwKTNz1JeIyEpckoSOmIISPiyAGMMPWEXjns+xHH3hzju+XDIXDmLuhh15nmoNc1FrWkOqk2zoFHoMrpWRcSDklMvwnn8GRjcx+XxgHUWOmbdgM66qyBoLBld01RAFBn6gtEhu3l3+SLo8UeGLNWVikrBSf3gjP1iJgudWQuzVpn3OXEjhXLniNFAwpcBGGPoDrfLQnfC89EgoeM5BaaZZqPONA+1CWvOpnFk58LFGExde1B6fAuKT78spx8ICi26p12Bjlk3wOdYQgEqZ4ExBk8ohk5vBJ3eMLr8A4Utetamp4BktdiTzU6NGjjMCVFLCJ1FrypYa4bnASXHS9GXJHTEKCHhmyQEFsdx94f4sOdtHOjZNUjoFJwS00yzMdOyGLOsizHdPC/j1txAlBE3HCf/jNLjW6D3NMjjAdtsuGZdj666qyCozVlcYW4Rjgno8iWEzReRRa4zIW7RYZqdJlHwHOxGtdzFW+rqrZV/txawsA0kackpOSkghYSOGA8kfBNMX6QTb7e/jJ2ul9OCURScErWmOZhpWYRZ1sWoywGhAwAwBnPHbjhPPAP76VfAJ6JEBaUO3bWfgWvmDYlcu8K70IjyPlu/oKWK3HB5bUk4Dig2qOEwa1GStNxSbja9ekoFkUwkqULHU+QlMcGQ8E0Qp7yH8Frz09jfs0tOFjeqLFhcfAEWFZ+PeusSqBW50/BUHeyA49SLKGl4Pq2Pnb9oLjpm3YCu2ishqMderSVfCEbisqB1eiNpItfli5zTHWnQKOAwaVFi1qDEpEGJWQtH4t5uVEOZ59VKMoXkupRy6EjoCgRO6kzBc9J+dSYh4Rsnp7yH8PKZ3+FQ3/vy2EzLIlxYdiUW2y+Ais+d5F5OiKCo+R8oaXgetrZ/gmOSQAtKPbpqr0THrOvhL14wJa07QWRo6gniRIcPJzp8aHdLlttwXbuTSO5IKXCkxKxJETnp3pDnFUqyQWpbHgpGmSJw0t+V5zhwHMAjcc8B3KCx/vskmgz3UaRP7RgZKHg8eKxyrsPayutQbpiW3cWlwhiMPftR0vAn2BtfgirqkQ95Spaha/p6dNdeAUFlzOIiJx5fKIYTnX6ccPlwotOPU53+IdvgAIBZp0pYaynClhC3IgO5I8cLNVnNL7iEWPGpP3MABy5dyAaM5RMkfKNkOMH7VPUX4NBVZHl1/agD7XA0voSShj9B7zkhj0f0Zeicfg06Z1yDsLk2iyucOETG0NoXkkSuwy9ZdJ7BXSb0agVmOI2Y5TShqlgvW21aVf5XI8kV0sp/JepckjWXJYaxwtKsLnksKW75J2JjgYRvhOSD4CnDfShuehWOU3+FueN9uVamoNCgp+YydE5fD0/paoDP7wt9NC7iVJcfx9p9OOryoqHDj2BUGDSv3KrFTKdJupUm2uAUwIc6k8jFnPlEMWcSuUljoJswaXGluhTz2QrLJCR85yDXBY+PBVHU/A84Gv8Ka+uOtC4IkivzGnRPuzyv0xCC0ThOuPw45vLiaLsPp7r8gwopa5Q8ZpQYMcNpwqxSI2aUmGDU0r/3REKdxCcBDuDR/6WB5xPCxUvWWJqg0fmeMOjKMAy5LHicEIW17Z9wNP4VRc3/gCIeko/5i+aiu/ZKdE27AlFj9oV5LHhCMRxr98oW3Zme4KDyXBadCvVlJswuM6O+1ISqIj0UtBc3YVAAyvhItcoGWmnS7/0/E5mHhG8AOSt4TIS5YzccjX9F8ZlXoIq45UMhU40kdrWfQcg6I3trHCPBSByH27w40OLBoTYP2t2D9+dKzBrUl0pCN7vMBKdZS9+AJxAKQBkBA8RrSFFL2TMjchcSvgTH+w7if489mVuCxxgMvQfhOPUS7Kf/Bk3QJR+K6hzonnYFumo/m3cJ5oLI0NDpx8EWNw60eHCy0z+oLmVVkT4hdCbUl5lRlOc933IJCkAZzECLjOcS7sbkz2SdTSlI+ADc+/a9+OvJvwLIvuCpgp2wtu+Ete2fsLbvhDrUJR+Lq0zoqbkMXXVXwuNclTdBKowxdHjDONDiwYEWDw63eREaEIxSZtFifqUF8ystmF1qpv25CYSSwyX4hNAnLVoFx8ljZKEVFnR1AVBvqwfPKbCq5NLMCp4Yh85zCoa+IzD2HIC1fScMfcfSpghKHfoqLkZX3ZXoq/g4mEKTmbWNE384jkOtktAdbPWgyxdJO27UKDGvwowFlVbMr7TAYcqP95XrJC0TaX8u4YorQKFT8BxUimRrIp7EjUiDhA/A5+o/hxr9cihRMmmvoYh6Yeg7Cn3vURj7DkPfewSGvmNybcwkDBwCxfPQV34BPGUfg7fkvLwQu3BMwHGXD4fbvDjU6kFjVyCtEaqC5zCr1IQFFRYsqLJgWrGBEsMnAEonkNyUyoTAKRUcVDxHIkeclZwQvl/+8pd46KGH4HK5sGjRIjzyyCNYsWJFxl5fp9Sh1FCJ7kD03JNHCB8Pw9K+E8XNb8Dseg8635kh5wlKAwJFsxGwzYHXuQLusjV50cw1GhdxokMSusNtXpzs9A+qa1lh08lCN7vMTIni4yTVmivkBqvJ969UJLqqcyR0xOjIuvA9++yz2LhxI371q19h5cqV+NnPfoZ169bh2LFjKCmZPAtsMuDjIdhat8F++u+wtbwFRTyYdjyiL0OgaA4CRXOle9schE3VAJfbhYyDkTiae4No6g1K9z1BnO4ODMqlKzaqMbfcjLnl0l4dBaSMHQ6JvbkCb6460JorZMEnJg6OsYEZUpll5cqVWL58OX7xi18AAERRRFVVFe6880585zvfOefjvV4vLBYLPB4PzOaxJ2kf6/SNyeLj4yHYWt6C/cwrsLW8mZZTFzaUo7fqk+ir+Dj89kWIa21jXl8miAsiXJ6wLG5JoevxD31erHoV5pabMa/CgrnlZjhMGvrmPQZSLTmeK1yXJTDQmuOhJHd4QaBR8rAbxrelMxotyKrFF41GsWfPHtxzzz3yGM/zWLt2LXbt2jXkYyKRCCKR/kAJr9c76escyFnFzliJ7mmXo6fm8pzudOAJRnGmJ5gmcm19IcSHacNTbFSjqkgv32odBpRZKJdutAwUuUK15IB+a06l4KVgFNqbIzJEVoWvu7sbgiDA6XSmjTudThw9enTIx2zatAk/+MEPMrG8NPJV7ASRod0dwpmeIJp6ArLIuYNDN1HVqvg0gasulu6p/c7oSSaFS0JXuBGWQCJ3MGnNJSw5qrRDZIu8u5rdc8892Lhxo/y71+tFVVXVpL2eofcwyg5vhv3MK2l7drkidowxhKIC+oIx9AWi6AtG4Q5G0e4Oo6kniJa+4KC9OEDaQ3JatKgu7he36iI97CYN7aGMkmR5Lyk3LOGqLMBzmEwCV6Qkf6fW9iSIXCGrwme326FQKNDR0ZE23tHRgdLS0iEfo9FooNFMcng/E2Fr3Y7yQ0/C6up3uWZa7KJxEb2BCPoCMfQFowlhi8GdELi+QAzuYHTYPnNJklZcTbEhTegoynL0FPR+nCxs/UKfas0WotgT+UlWhU+tVmPp0qXYunUrrrrqKgBScMvWrVtxxx13ZH5BYhyO039DxYFfweA+DgBgnALdNZ9C+5yb4HOcN2FiFxdE9AWj6PFLt95AZNDPvvDZu4OnolcrYDOoYdOrYTOoYDdqZKFzmMmKGwvJC3rSYuESLV+mMgOttv7qJtQhgJg6ZN3VuXHjRtx0001YtmwZVqxYgZ/97GcIBAK45ZZbMreIeASWQ39A9Z5HofM3SUMqIzpmXof2OTcjMsouB4wx+MJxdPsj6PFFpXt/BD2BhLD5I3AHYxhJOK1GyaPIoIbVoIZNr0oImxpWvUoWOqteBQ1Zb+NCkbYfN7Wtl2StTlnQUgpUU1EBohDIuvBdd9116Orqwn333QeXy4XFixfj1VdfHRTwMqk8cz1KT74JAIhpitA29xa0z/7iiHvYhWMCDrZ4cLzDh8auAE53B4ZsjDoQJc+hyKhGsUGNIqMGxQY1io1qFBs18r1eraBv2RNMWpFmvr9551QiGUySGlyTFLapLOoEMRKynsc3XiYkj+/A84i9+h9onnc7OmZeB1GpO+dD3MEo9p7uw54zfTjU6hkygMSql1yOA8WsOCF2Jp2KLkIZIK2Bag4VaZZcp5L7MO1n+RgnzwOk40jMA1Ifk+jEnXKcviwRuQg3YI84+blUKTholOPzWuVNHl/OMO9qnLJfjO7BbeBkGGNodYew53Qf9pzuw8lOf9pxp1mD+ZUW1DmMqHUYUG7VQaXI7YosU5Wk0CknqxvBECLV34ctIUIDf07M5xPzSZiIqYRUaYhLaXfFpYhb7nkbSPgAqb2PQg2gv0IJYwwuTxjHXD4cd/lwtN2LDm96h4E6hwHLphVh6TQbKmw6uphlibEIXTKII7UPGzeUFTWMgBFEITCUoPX/jrzdEyfhSxATRDR0+GShO+7ywTsgqlLJc5hbYcbSaUVYWmODjWpRZpxkztxIKp+k7nOlfvuk0Hui0Ble0NLdkFP1c0LCB+CHLx3GH949g6iQng+n5DlMLzFiVqkJs5wmzC43Qa+mU5ZJztVEdThxo4r9RKGiKGBBGyl0FYeUAxcVRBg1SknkSk2oLzWh1mGgfboMkmrNKRKdCZJRiTzf75JMWmyUV0YUEqmBIalRyelf+ujzMBJI+ADcsLIai6qt0GoUBf9NKFMkUwrUCh4qJQc1z0OpSLTgSUY50t+i4InFYvif3zyJ3p5ufOu735PHL1mzHB3t7Xjxta2YMaseAHD4wH58686vobyyCk/+YYs8lzGGaDSaVvFpz+73sX/fHsxfuBjLV63O3BsahtRCCXJe5QCBo2vTxEHCB6DCqoM/Gp/QRrSFjBzpmBI8krTmkmHL6kRFfmJyicVieOCH96Ox4QR+88xz2V4OACDg92PvB++DMYYLL75EHt/6+qt48/VX8YlPrsMl6z4FADi4/0Pc9+278Omrrkl7Do+7D+6+XoSC/fVz//THLdj/4T4sWd7fxJoxho+dtwBNpxtxutsLhUIKmf/bC3/CE48+gq/+n2/KwheNRvGTB36E6mm1+NwNX4BKpRr2PXjcbnR2uMBxnCy8Q5HWiWOAZUZu+exBfjwCQEKskKxF2f8hVSZuKp6DWiFZaBoFD42ShzZx06l46FUKGNQKGNUKGDVKGNRK6FQKGNRKmLVKFBnUsBvUsOrU0KkUGRc9URRx4MAB7NixAwcOHIAonr2+aa4w3nU//F//iccf+RkuuPgTSKbsut19+L/3/wcajh+T50UiERw+sB/tba1pj+/scCEcDiMa7f9SePLEcbz4/B+x94P30+aeajiBUw0n0sae+f1vcdGKJfjN44/JY60tzbjhqk9jw603p839y/PP4XdP/hptrS3yGM/zsDtKcNEln0yb+/SfX8K29/dh5uw58tgNX7wJm595Dhu+fpc8tm/PbpxpPAXGGDzuPnl8weIluOKzV2P2nLny2Patb+AXP3kYv/zJw1Aq+22CxTOnodZhQUuTVNVJwXF4/un/wcUrz8M3v3objGolzFoVbDoV/vHXP+PIB7vgNGpQbtaizKzF8Q93Y8drL8Pb1Q6zVgWjRglOiOHE0cNoOn2aRC8LkMU3BegPv+93Dw4MwR84lnwcMLEuRY4DVAoeKgUHFZ8bVt077+zCE088gZ6ebnmsuNiO22+/HWvWjMzNJYoiDh06hL6+PthsNsybNw88P7nfGydi3bf/2x14e/tbcJQ4wXEcIpEIPv/py3D44AFUVFbK1kpbawsuvWAVlixbjpf+sV1+/I3XfBZHDh3AGzvfx5x58wEA27b+A/d/51v4zNXr8djm/5Hnrr/8k+jr7cW+442wFRUDAA4e+AgNx48hHO5v42U0mjB77nxYbba0ta5YswZGkxErVp8vj82dvxB7jp6ULbUks1IEL8mMWfWDrK/F5y3D3mOnoNZoYLFY5fFrPn89rvn89Wlzi+3FuPGmm7Fs+QqYtSrZKovHoojFYjApRVRYpOIW5Y4i2Gw23PrlW2DRSZZhc3Mzbv7SF1BaWor29nb5eR944AG8/PLLeOqpp/DlL38ZAHDs2DEsXrx40Ny7774bXV1duOuuu7BgwQIA0peSUCgElUoFg8Ew6H0To4eEL4fhU9yFqSLWP5b9fTCO628mmrQOs72mVN55ZxceeOABYEBl1J6eHjzwwAP4zne+c04RmQgBGi3jWXcoFIJOJ12g7Y4SvPSP7bJIazQabPjmt/DnPz6D6mm18mOEeBwlTicajh9Da3MzKhKtvpK1O0WhvwSfs6wMay74OGbPnZf2unq9AZFwBHvefw9rL7scAHDFlVdj1ZqP4fwLPy7PK6+sxD/eSbcWAeALN986aOxs7saRwPM8SpzpnV5UPA+lov9/VqWQ9tIq1l6Mz6y9eNBz7NmzB2q1Oq1jzG233YbbbrstbV5TUxOuuOIKtLS0pI3PmTMHfX19KC8vl8cYY3A4HCguLpbHotEonnrqKfT19eGLX/yiPP7EE0/gzjvvxOc//3k8++yzACQX9u9//3tMnz4dF110Udoa4vE46urqAEhf2JqamqDX6+FwOOTP5kcffQSr1YqampoRncepBpUsS3Cs05e1Pb6kazE9ejF3xGMgHAfJ5ankc07oUhFFEbfeeht6errR19UBIR6DvaxSPt7b2YHK6mo8veXZYa234QQoaS+PRDjHs24ACIeCaD99CmZbEYpLywFwsNuL4e1oQTgcxpYXX4bRZAIA/PdDD+Ch//tD/PzXvxlk0YyFcDiMlqYzqJ0+Y5DVlesoEl/IVDn8xSwVxhjeeecdvPDCC3jwwQfl8/2LX/xikPA1Njairq4ONTU1OHLkCHQ6HV555RVcfvnl+P73v4/7778fQP/1EZC+EGm1Wni9XixevBinT5/G1q1bcfHFg8U+HxmNFtAeXwZJBnioFRy0Sh4GtQKmxH6YVqWAWslDyfM5K3oKnoNBrYBNJ+1TqBR8zl1EGGMI+P3ocLXj0KFDsug1HjmAjpamtLkdzY14+/WX8be//kUee/3vf8Mnz1+J+779LYiiiCeeeAIAQzQSRvp3RAbGGJ588okR7bt1dXag+cwZ+ffGUyexeuEc3HL9tejr65XHjx89gqcefwytzf1z/e5e9HW54Pe65dfu7u7Guzvfxod7PkAwGJDnKhJ7U7/6+U8nZB9Tq9Vixqz6nBY9nuOgUfIwapSw6VRwJPbXSk1aFOvVMGtV0KkUOfn/mgrHcTj//PPx8MMPp53vr33ta4hGo/jf//1feezxxx8HAGzZskW27v/+97+D4zgUFRXJ85LWP8/zclSr2+3GtGnTYDabsXp1/5e25uZmdHf3ezWmMiR8kwjPAWoFB11C5IwaJfQqBTRK6UOYqwKXBie1RjJrlbDqVNCqcrtbxHvv7ER9ZQmuvWId+vqkYAaT1QZLsQMqdXoDY51RspK8Ho881tnZgSOHDqC1uUkWTsYYTuzfi4aD+9Ie33a6AXve+ScOHDggj2197RX8/OEHsef99+SxbVvfwKqFc/C1L38RsVgMADCttg4cx+GNV/8OlbLfnffXPz+PH9xzNzpbm+Uxq90JvckMg8mS9vp33n0PfrvleZjM/eNf+vLt+OBIA17Z/s6k70FmGg6Sp0GvVsCiVcFuUKMsEUBiN2hg0aqgVyuhznGBGy0KhQIqlSot4GbTpk2IRqNYtWqVPHb99dejqakJd955pzzmdDoRDAYRi8Xkc1JdXY0333wTjY2N0Gq1ACTL/oorrkBZWRlOnOgPUDp8+DCef/55HDlyZLLfZkahPb6zIDIRXV1diITD0Gi1cDgc4LmzX0w49Ad35IWwDQPPS1apRpk7At3X14tf/ORh3HnX3bBabUPOKUrsmQT8PtgSwRNKlRp1cxcOmjutfh4q62ZizvwF8tgll16Gp194CRarVRbOaCQs34R4HAqlEowx9Ha0gTGGjo4O+fEv/+UF/PHpP+Ce7yuxdMVKAMDCxUsgxOMQ4nF0d3WirLwCHMfh57/+DT7atxcGo1F+fInTifo58xCIxOQxpUqF2Uv6Q/STXH7lVXIARBKzxQKzxTJobr7BJ3M8Ff3uSiUVk5DhOG7Q/uf5558/zGwM+SXIlhJcdPToUSiVSsTjcTgcDnn8xRdfxL333oubb74ZmzdvBgAIgoAdO3bktYuUhG8YmltasG/vXgRD/XlCep0eS847D1WVlYPmcwDUSukDmrffNhN7d1oln3MVa4KBAD79iQtxpvEU6mbMwI03SdFxf3r2Gfzuycex+ZnnUGx3YPrMWTje2gWdXg/GGIqL7ejp6cHQfxIOpWXlWLJkiTxSVl6BsnKp8XDSktNodZhz3kr43L1gib0+juNQPm0GWk4dRyzS39Zj1fkXQKFUpgV+FBXbsW33h6iZVpv2v7Fs5SosW9n/jR0AvnTrV/CFW25L7PH1YPDeorRuu70Y8+bNG+JY/iG5//v34lSU45lxFi9ejL179+LkyZPyniAAlJSUYM2aNVi0aJE8tn37dlxyySXYvHkzbr755iysdvzk1tUtR2huacHOnTvTRA8AgqEQdu7cieaUqC2Og7xfl68uFp6TyrbZdCqYEnt3uQbH87jjm9/CxZ+8FDNnzZbHn3v6D9i7+3187tOXQRRFKBQK6A0GqQUQz+P2229PPsPAZwQA3Hbb7cO6BOfNm4fiYjsADlq9AY7yKihT3JLFpRW45Mpr8akrPi2Pff7GL+Khnz+KSy69LO25kq7NkTDedecyCp6DTqWAOcVVWWrSokivhkkrudJJ9LLH9OnT0/5Pb7vtNuzcuRPf+MY35LFTp06B4zj88Y9/BCDtDb7wwgsYGCc5krhJQRDg9/vPOW+ioajOBMmoTpGJ+NtLfxskev1w0Ot1uPIzn4FWqZjwKDGRSeHHAb8fBqMR1dXV53SvDkQQBIiieM5QcJWCg1apgEqR21YqY2zY9R0/egTHjx7BwsXnoXratCHnDJWOYLfbcdtt505H6I/qBNKtr8mL6kx97bGuOxdQplhw6oTLMlfc5sT4OH36NJqbm7Fy5UrU19fj9OnTeOyxx/DVr34VLpcLl19+OVpbW9He3i5/Qfv5z3+OX/3qV/jCF76A7373u2CM4eqrr4Zer8fTTz897jWNRgtI+BIkha+jswNvvfUWBEFA84kjqJpRD4VSBcYY3t/6dyiVKkyfvxjXrr8GtTXTJu6NADhy9Chef+01eH1eecxsMuPSdeswZ/bsszyyn77eHtx4xScQ9Pvxw58+igvXrks7ruClCLh8KBl2quEE/t+mH2HOvPm4Y+Pd43qu8SSgZ1OAspE4PxaSIpe6L0ciVxh8/etfx89//nO89957WLFiBWKxGPR6PeLxOJqamlBVVQXGGOrr69Ha2oq33noLK1aswN69e7Fs2TJ8//vfxz333DPunE3qwD4OIuEwwqEgnn/s/8Hd1YHLv/gV1NTPw+tbNuPkwQ9hL69ERd1MBBPm+X9v+gEYY7jpq3fK1SrGwpGjR/H8889j4J6O1+fD888/j2uvvXZE4mcrKkZ17XTs2v4m9IkqDwqew5GP9sJmMWP6jBlQqXI3ND2Vj/btxV/+9By2v7kVt37tDjlseyzwPD8oEGSkrFmzGqtWrcyKAI1n3ZOFik8JOpkCgVzE+PjJT36Cn/70p/LnQaVS4ZVXXkF1dbWctC+KIjZt2oRQKITly5cDAJYsWYKamhoIgjBu0RstJHwD0Gi1UGu0mLN0FfZufwMhvw++3m7UzlkAo8UGTeLiazAaIYoi/vi7p+D3efHZz//LmIVPZCJef+01pIpeLBpJhN8zABxef/011NfPGpHbc9MvnoCrpQnnLV2WyA3k8B8b78Cxw4fw++dewCc+KVmBuWZNeD0eNJ1uxPxFiwEAV15zLfa8/x7+5Us3j0v0JoJcFKDJpj9COT26Mpfd4kTmGSrHc+3atYPmrF+/Pm2M4zi8+uqrmDVr1qSubyhI+CAJwP88+Svs2L4NP3p0M4wGIxau/jim1c9DLBpBOBSE1V4Cq70EAAez2YTq6moIsTju+PZ/4PTJE2m5VKPdp2tqakpzbwLArtdegqO8EvWLl4NXKOD1etHU1IRpQ7hX3b29ePutN3DF1eth0GpgrSjFjKoy+ThjDGazGQajUQ4MeeedXfj1r3+N3t4eed5kl+E6Fw/88D7sef89OQdNoVDgRw/9JCtrKTR4TirdpU4KHaUPEBmgvn74zhaTCQkfpIKxD97/XRjNFvCiiCUL5+NPz/1xiJnSN91LL10HnuPBq9W44ZavyEcZY3joP++DqNQillI141z7dAG/H2eOHQbP86iaORuxaBSxSBiH3t8JURQxb/kaeV7aajjJ7fT875/AIw9two5XX8JTTw9eN8dxeOHVrXKU1Tvv7MJ3v303WhtPoLJ2Jkw2qdLDaOpXTjSMMbz+ystwtbVh545tuOCiT2T09QuJ1KCTZApBru/3EsREQsIHqYjsg488jheefxY97c2YWz8L3LXXDg40MZtw6aXDC9gPv3MX/vyH36C4tBwXXXW97BI61z6d3mDA0b3vwufug0KlQllNHapmzsa8FR9DafU0AJLrU6vTyXUyk0EEHMehqqoSVlsRrj5HbUaO4+QyXD2uNoT8Pvi9bln4km7VJ598AqtWrRzS7RmLxWRrbCLhOA5/fX0b3tr6OpavWjOhz12IcACUKfUppZtUnJn244hCh4QvweevvwFrr+z3Qc+ZPRv19bNG7LIUmQhOa4RGp8e02fP7q6C/sw1MFDFt9gJ5n87T14e//vFpaLRaXH/z7Sh1OlE9YzZOHz8CR3klOI7DrEXL5OeORaI4uGs7bnzmN/ju/f+JW/71a2mv/S9fugVXXHk1TCOIak2W4aqaWQ9RiMNWUjpghlQH8tChQ0PuaT37h9/hpw/+F/71jm/gK3f8HwiCMGYRdLv7cPzIEcyYNQtFxXaUV1bKienEueE5SdAUA8Qt2bGbIIihIeE7CzzHD7mnNhRNTU3gVCp88vNfgkanl8djkQhOHz0Ic5EdVrsDTU1NECJh/OQ/vwdbUTGuv/l26HR6fO/Bn+K5554Dl+j/FQ74EQr4EQ4GEItGoVZwCAWDKLLb5edmjKGrswMlzlJYrNYRrTNZhiuZlpFEFEX0dblQVFIGjuPkeZ0dLgCQW7uUV1ahw+VCOByCKIq44apP48SxI9h3/LT8XP/1/e/hlZf+gkef+h0WLJaqohw/egRvvvEaPnbhRXLwyv3fvht/evZprLv803jyf5+loIkhGCxuCSuOLDeCGDMkfBNEcv9Nq09vFDl9/mJwPA9joglmwO+HvagIn7n2euiNJnCJlkSL588FF7sSm596QhYboD9fbOXKFWg82QBHiRMA0NbSgjtuvxlFxXY88T/PjFg0bAOafwKS6B3/6AMEfV54erpQN3cRbDYb/vN738Xjj/wMd2z8Fr5z3w8BAB//xFosXbES133hS9i5Yxve+ed2mFMCew7t/wiP/fdPwBiDSq2Wx/fufh8/+t53cfmVV+HXv5eSVb//wI/x4d4PoFAq4fG4h62/OdVJilvypiBxI4hJhYRvgkgtNJyKze7EwlUXIBaJwtPTBbNeixnTqvHIr5+EgksPDT9/1XKsXrF02BSD1O7SVpsNbS0teH/XO/jqzV/A47/730GvPRTJMlypdSB5nkdJRTWaG46hrGY67HY75s2bh0Oz6sFxHLpSijArFAr85fW3AADO0jI8+9dXEA4F5eoqcxcsxPYPPkKny4Wa2jr5cVXVNbj689fDZDLJc222Imzf/eGI1p3vDBK3lP03EjeCyCxUuSVBizuE3uDYG9GKTMQjP38EXp8PsUgIQb8PIb8PoWAATBSRLCz85JNPTliunNvdh5MnTmDO3HlysvpIGK4MFxMZOJ6XozoDfj/i8fiI3aiFzkB3pILvd1OSuBHE5EIly8bAeISP46RE3/379uHhHz8AIR5Hpus6jpZ8rwOZLZL5bvJeW4q40R4lQWQPEr4xMBrhS+bPKRPVLJQpEXT5JCi5Vrkll0gKnPx3plQAgshpSPjGwNmEj+NSk36lb/tngwQlf0i14FLvSeAIIr+gItUTQSJRXJOSKD5SCrGuY76Q7EyhpoanBFGwkPANQKngoFHwUCuprcpUQaPkoVMpoFMp6G9KEAQJXxKNkodVpyILYIqgVvSLHf1NCYJIhYQvgVrBIyqI555I5CyqFLFTktgRBDEMJHxEXqPkOeiTYkdtdAiCGAEkfETeoeQ52bJTkdgRBDFKSPiIvECRYtmR2BEEMR5I+IicheM46JQ89GoFNMqJ7f9HEEThQsJH5BxapQI6tQI6JU9lwAiCmHBI+IicQMFzMKiV0FP6AUEQkwwJH5FVtCoFjOTKJAgig0xKlMDp06dx6623ora2FjqdDtOnT8f999+PaDS9Fub+/ftxwQUXQKvVoqqqCj/+8Y8nYzlEjsFzHEwaJUpNWhTr1SR6BEFklEmx+I4ePQpRFPH4449jxowZOHjwIG6//XYEAgE8/PDDAKSCopdeeinWrl2LX/3qVzhw4AC+/OUvw2q14itf+cpkLIvIMholD4NaCS3t3REEkUUy1p3hoYcewmOPPYZTp04BAB577DHce++9cLlcUKvVAKR+dS+++CKOHj064uedqO4MnlAM/mh8zI8nhkbBcdCrFdCrlVRNhSCISWM0WpCxhCiPx4OioiL59127duHCCy+URQ8A1q1bh2PHjqGvr2/Y54lEIvB6vWk3IvfQqhQo1qvhNGlg1qpI9AiCyBkyInwNDQ145JFH8K//+q/ymMvlgtPpTJuX/N3lcg37XJs2bYLFYpFvVVVVk7NoYtQkC30n9+60KgW5NAmCyDlGJXzf+c53wHHcWW8D3ZStra247LLL8LnPfQ633377uBd8zz33wOPxyLfm5uZxPycxdlQKHhatJHZ2gwYGtZLSEQiCyGlGFdxy11134eabbz7rnLq6OvnntrY2XHzxxVizZg1+/etfp80rLS1FR0dH2ljy99LS0mGfX6PRQKPRjGbZxARD5cMIgshnRiV8DocDDodjRHNbW1tx8cUXY+nSpdi8eTN4Pv0CuXr1atx7772IxWJQqVQAgDfeeAP19fWw2WyjWRaRAVQKHtpEQ1cSO4Ig8plJuYK1trbioosuQnV1NR5++GF0dXXB5XKl7d39y7/8C9RqNW699VYcOnQIzz77LP77v/8bGzdunIwlEWNAo+x3Y5YYpSAVEj2CIPKdScnje+ONN9DQ0ICGhgZUVlamHUtmT1gsFrz++uvYsGEDli5dCrvdjvvuu49y+LIIx3HQKnloVQpolTx4CkwhCGIKkrE8vsmC8vjGh4LjoFUpoFPxUCsosZwgiPxkNFpAtToLENqvIwiikCHhKxDUCknotCoeSp7EjiCIwoWEbwqjSVh1WiW1+iEIgkhCwjdFUPAcVDwPpYKDWsFDQ8EpBEEQQ0LCl2fIAsdzUCr6xY5EjiAIYmSQ8OUoCp6DSsFDzXNQKhJCx3MUdUkQBDFOSPhyABXPQ6WQhC55TxYcQRDE5EDCl0E4ICFuKUJHVhxBEERGIeGbJJIip04ROnJVEgRBZB8SvglEo+ShUSqgUZIlRxAEkauQ8I0TtYKHXi216KF9OYIgiNyHhG8MKJP96NRKKCkxnCAIIq8g4RshPMdBp1JAr1JAraSSXwRBEPkKCd850CbETqukzgUEQRBTARK+IaB9O4IgiKkLCV8CpYKDWauCTqWgfTuCIIgpDAlfAoOaTgVBEEQhQFEaBEEQREFBwkcQBEEUFCR8BEEQREFBwkcQBEEUFCR8BEEQREFBwkcQBEEUFCR8BEEQREFBwkcQBEEUFHmftc0YAwB4vd4sr4QgCILIFkkNSGrC2ch74fP5fACAqqqqLK+EIAiCyDY+nw8Wi+Wsczg2EnnMYURRRFtbG0wm05i7J3i9XlRVVaG5uRlms3mCVzi1oHM1cuhcjRw6VyOHztXQMMbg8/lQXl4Onj/7Ll7eW3w8z6OysnJCnstsNtM/0gihczVy6FyNHDpXI4fO1WDOZekloeAWgiAIoqAg4SMIgiAKChI+ABqNBvfffz80Gk22l5Lz0LkaOXSuRg6dq5FD52r85H1wC0EQBEGMBrL4CIIgiIKChI8gCIIoKEj4CIIgiIKChI8gCIIoKEj4CIIgiIKChA/AL3/5S0ybNg1arRYrV67E+++/n+0lZZTvf//74Dgu7TZ79mz5eDgcxoYNG1BcXAyj0Yj169ejo6Mj7TmamppwxRVXQK/Xo6SkBHfffTfi8Xim38qEs2PHDnzmM59BeXk5OI7Diy++mHacMYb77rsPZWVl0Ol0WLt2LU6cOJE2p7e3FzfeeCPMZjOsVituvfVW+P3+tDn79+/HBRdcAK1Wi6qqKvz4xz+e7Lc24ZzrXN18882D/s8uu+yytDmFcK42bdqE5cuXw2QyoaSkBFdddRWOHTuWNmeiPnPbtm3DeeedB41GgxkzZuC3v/3tZL+9/IAVOFu2bGFqtZr95je/YYcOHWK33347s1qtrKOjI9tLyxj3338/mzdvHmtvb5dvXV1d8vGvfvWrrKqqim3dupV98MEHbNWqVWzNmjXy8Xg8zubPn8/Wrl3L9u3bx/7+978zu93O7rnnnmy8nQnl73//O7v33nvZn//8ZwaAvfDCC2nHH3jgAWaxWNiLL77IPvroI3bllVey2tpaFgqF5DmXXXYZW7RoEXv33XfZP//5TzZjxgx2ww03yMc9Hg9zOp3sxhtvZAcPHmTPPPMM0+l07PHHH8/U25wQznWubrrpJnbZZZel/Z/19vamzSmEc7Vu3Tq2efNmdvDgQfbhhx+yyy+/nFVXVzO/3y/PmYjP3KlTp5her2cbN25khw8fZo888ghTKBTs1Vdfzej7zUUKXvhWrFjBNmzYIP8uCAIrLy9nmzZtyuKqMsv999/PFi1aNOQxt9vNVCoVe+655+SxI0eOMABs165djDHpgsfzPHO5XPKcxx57jJnNZhaJRCZ17Zlk4MVcFEVWWlrKHnroIXnM7XYzjUbDnnnmGcYYY4cPH2YA2O7du+U5r7zyCuM4jrW2tjLGGHv00UeZzWZLO1ff/va3WX19/SS/o8ljOOH77Gc/O+xjCvVcdXZ2MgBs+/btjLGJ+8z9+7//O5s3b17aa1133XVs3bp1k/2Wcp6CdnVGo1Hs2bMHa9eulcd4nsfatWuxa9euLK4s85w4cQLl5eWoq6vDjTfeiKamJgDAnj17EIvF0s7R7NmzUV1dLZ+jXbt2YcGCBXA6nfKcdevWwev14tChQ5l9IxmksbERLpcr7dxYLBasXLky7dxYrVYsW7ZMnrN27VrwPI/33ntPnnPhhRdCrVbLc9atW4djx46hr68vQ+8mM2zbtg0lJSWor6/H1772NfT09MjHCvVceTweAEBRURGAifvM7dq1K+05knMK7do2FAUtfN3d3RAEIe2fBwCcTidcLleWVpV5Vq5cid/+9rd49dVX8dhjj6GxsREXXHABfD4fXC4X1Go1rFZr2mNSz5HL5RryHCaPTVWS7+1s/z8ulwslJSVpx5VKJYqKigru/F122WX4/e9/j61bt+LBBx/E9u3b8alPfQqCIAAozHMliiK+8Y1v4Pzzz8f8+fMBYMI+c8PN8Xq9CIVCk/F28oa8b0tEjJ9PfepT8s8LFy7EypUrUVNTgz/+8Y/Q6XRZXBkxlbj++uvlnxcsWICFCxdi+vTp2LZtGy655JIsrix7bNiwAQcPHsTbb7+d7aUUFAVt8dntdigUikHRUh0dHSgtLc3SqrKP1WrFrFmz0NDQgNLSUkSjUbjd7rQ5qeeotLR0yHOYPDZVSb63s/3/lJaWorOzM+14PB5Hb29vwZ+/uro62O12NDQ0ACi8c3XHHXfgb3/7G9566620nqIT9Zkbbo7ZbC74L7QFLXxqtRpLly7F1q1b5TFRFLF161asXr06iyvLLn6/HydPnkRZWRmWLl0KlUqVdo6OHTuGpqYm+RytXr0aBw4cSLtovfHGGzCbzZg7d27G158pamtrUVpamnZuvF4v3nvvvbRz43a7sWfPHnnOm2++CVEUsXLlSnnOjh07EIvF5DlvvPEG6uvrYbPZMvRuMk9LSwt6enpQVlYGoHDOFWMMd9xxB1544QW8+eabqK2tTTs+UZ+51atXpz1Hck4hX9tksh1dk222bNnCNBoN++1vf8sOHz7MvvKVrzCr1ZoWLTXVueuuu9i2bdtYY2Mj27lzJ1u7di2z2+2ss7OTMSaFVldXV7M333yTffDBB2z16tVs9erV8uOTodWXXnop+/DDD9mrr77KHA7HlEhn8Pl8bN++fWzfvn0MAPvJT37C9u3bx86cOcMYk9IZrFYr+8tf/sL279/PPvvZzw6ZzrBkyRL23nvvsbfffpvNnDkzLUTf7XYzp9PJvvjFL7KDBw+yLVu2ML1en1ch+oyd/Vz5fD72rW99i+3atYs1Njayf/zjH+y8885jM2fOZOFwWH6OQjhXX/va15jFYmHbtm1LS+0IBoPynIn4zCXTGe6++2525MgR9stf/pLSGRIUvPAxxtgjjzzCqqurmVqtZitWrGDvvvtutpeUUa677jpWVlbG1Go1q6ioYNdddx1raGiQj4dCIfZv//ZvzGazMb1ez66++mrW3t6e9hynT59mn/rUp5hOp2N2u53dddddLBaLZfqtTDhvvfUWAzDodtNNNzHGpJSG733ve8zpdDKNRsMuueQSduzYsbTn6OnpYTfccAMzGo3MbDazW265hfl8vrQ5H330EfvYxz7GNBoNq6ioYA888ECm3uKEcbZzFQwG2aWXXsocDgdTqVSspqaG3X777YO+YBbCuRrqHAFgmzdvludM1GfurbfeYosXL2ZqtZrV1dWlvUYhQ/34CIIgiIKioPf4CIIgiMKDhI8gCIIoKEj4CIIgiIKChI8gCIIoKEj4CIIgiIKChI8gCIIoKEj4CIIgiIKChI8gCIIoKEj4CIIgiIKChI8gCIIoKEj4CIIgiILi/wPDuwa5FfYMNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/100000 [00:00<7:09:23,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "4.5386550839199945e+21\n",
      "tensor(4.5387e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5024.7119, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/100000 [00:00<6:10:27,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.220689218688237e+21\n",
      "tensor(5.2207e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9171.3916, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/100000 [00:00<6:06:29,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.345049366998632e+21\n",
      "tensor(5.3450e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5130.4971, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/100000 [00:01<5:35:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "2.584300750095872e+20\n",
      "tensor(2.5843e+20, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5139.6650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "3.1738656754931765e+21\n",
      "tensor(3.1739e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5161.1865, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/100000 [00:01<5:19:05,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "2.4241187944275116e+21\n",
      "tensor(2.4241e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5218.7485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.75395425811569e+21\n",
      "tensor(5.7540e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5267.0596, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/100000 [00:02<5:21:53,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.644596163114019e+21\n",
      "tensor(5.6446e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5285.2490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.366474679275894e+21\n",
      "tensor(5.3665e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5328.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/100000 [00:02<5:21:15,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "4.95247621698028e+21\n",
      "tensor(4.9525e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5366.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/100000 [00:02<5:51:57,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.459048421416308e+21\n",
      "tensor(5.4590e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5387.7646, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/100000 [00:02<5:35:25,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.179978929856622e+21\n",
      "tensor(5.1800e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5398.5122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "4.665877832743537e+21\n",
      "tensor(4.6659e+21, device='cuda:0', grad_fn=<MeanBackward0>) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/100000 [00:02<5:41:41,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5419.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.748925426181777e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/100000 [00:03<5:45:07,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7489e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5435.1211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "4.15598366063237e+21\n",
      "tensor(4.1560e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5451.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/100000 [00:03<5:38:49,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.800559758859534e+21\n",
      "tensor(5.8006e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5470.9956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.382229396672343e+21\n",
      "tensor(5.3822e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5477.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/100000 [00:03<5:41:22,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "2.7148064471259074e+21\n",
      "tensor(2.7148e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5491.4434, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/100000 [00:04<5:36:44,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.513760401489419e+21\n",
      "tensor(5.5138e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5498.8965, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/100000 [00:04<5:37:30,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.795325450192622e+21\n",
      "tensor(5.7953e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5497.8691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.59104104519519e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/100000 [00:04<5:44:48,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5910e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5492.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "5.479282531592131e+21\n",
      "tensor(5.4793e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5534.6138, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/100000 [00:04<5:47:35,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "3.792975234792822e+21\n",
      "tensor(3.7930e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9470.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/100000 [00:05<5:24:59,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "8.310810459110459e+20\n",
      "tensor(8.3108e+20, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5542.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "4.140752486692603e+21\n",
      "tensor(4.1408e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5562.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/100000 [00:05<5:52:13,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 288])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "3.3641849809960866e+21\n",
      "tensor(3.3642e+21, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5582.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 85\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)):\n\u001b[1;32m     83\u001b[0m     batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgenerate_batch(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice, return_knowledge\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_knowledge)\n\u001b[0;32m---> 85\u001b[0m     p_y_pred, q_z_context, q_z_target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknowledge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(p_y_pred\u001b[38;5;241m.\u001b[39mbatch_shape)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(q_z_context\u001b[38;5;241m.\u001b[39mbatch_shape)\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/kas/informed_nps.py:43\u001b[0m, in \u001b[0;36mINP.forward\u001b[0;34m(self, x_context, y_context, x_target, y_target, knowledge)\u001b[0m\n\u001b[1;32m     40\u001b[0m x_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_encoder(x_target)  \u001b[38;5;66;03m# [bs, num_context, x_transf_dim]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m R, R_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_globally(x_context, y_context, x_target)\n\u001b[0;32m---> 43\u001b[0m z_samples, q_z_Cc, q_zCct, k_deter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_latent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknowledge\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# reshape z_samples to the shape of x_target\u001b[39;00m\n\u001b[1;32m     48\u001b[0m R_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependent_representation(R, R_deterministic, k_deter, x_target, z_samples)\n",
      "File \u001b[0;32m/home/w/IML/kas/informed_nps.py:121\u001b[0m, in \u001b[0;36mINP.sample_latent\u001b[0;34m(self, R, x_context, x_target, y_target, knowledge)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    120\u001b[0m     R_from_target, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_globally(x_target, y_target, x_target)\n\u001b[0;32m--> 121\u001b[0m     q_zCct, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_latent_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_from_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     sampling_dist \u001b[38;5;241m=\u001b[39m q_zCct\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/w/IML/kas/informed_nps.py:142\u001b[0m, in \u001b[0;36mINP.infer_latent_dist\u001b[0;34m(self, R, knowledge, n)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mknowledge_dropout:\n\u001b[1;32m    140\u001b[0m     knowledge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m q_z_stats, k_deter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m q_z_loc, q_z_scale \u001b[38;5;241m=\u001b[39m q_z_stats\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_dim, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    144\u001b[0m q_z_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.99\u001b[39m \u001b[38;5;241m*\u001b[39m F\u001b[38;5;241m.\u001b[39msoftplus(q_z_scale)\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/kas/modules.py:354\u001b[0m, in \u001b[0;36mModulatedLatentEncoder.forward\u001b[0;34m(self, R, knowledge, n)\u001b[0m\n\u001b[1;32m    352\u001b[0m     modulating_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     modulating_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknowledge_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modulating_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m     q_z_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(R)\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/kas/modules.py:396\u001b[0m, in \u001b[0;36mModulatingKnowledgeEncoder.forward\u001b[0;34m(self, knowledge, R)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, knowledge, R):\n\u001b[0;32m--> 396\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtext_encoder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    398\u001b[0m         k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/kas/modules.py:125\u001b[0m, in \u001b[0;36mRoBERTa.forward\u001b[0;34m(self, knowledge)\u001b[0m\n\u001b[1;32m    122\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m knowledge[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    123\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m knowledge[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 125\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#hidden_state = llm_output[0]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_cls:\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:410\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    400\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:337\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    329\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    336\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 337\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    347\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:256\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    253\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m/home/w/IML/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1855\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a softmax function.\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \n\u001b[1;32m   1858\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \n\u001b[1;32m   1879\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "import sys\n",
    "import os\n",
    "from kas_loss import ELBOLoss\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(os.getcwd())\n",
    "from data_utils import get_dataloader\n",
    "# from dataset.datasets import NewRegression\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from temp_data import Temperatures\n",
    "from informed_nps import INP\n",
    "from plot import plot_predictive\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.tempdata import TempData\n",
    "\n",
    "\n",
    "config = Namespace(\n",
    "    input_dim=1,\n",
    "    output_dim=1,\n",
    "    xy_encoder_num_hidden=2,\n",
    "    xy_encoder_hidden_dim=128,\n",
    "    data_agg_func='sum',\n",
    "    latent_encoder_num_hidden=2,\n",
    "    decoder_hidden_dim=64,\n",
    "    decoder_num_hidden=2,\n",
    "    decoder_activation='gelu',\n",
    "    hidden_dim=128,\n",
    "    x_transf_dim=128,\n",
    "    x_encoder_num_hidden=1,\n",
    "    test_num_z_samples=32,\n",
    "    train_num_z_samples=1,\n",
    "    knowledge_extractor_num_hidden=0,\n",
    "    knowledge_extractor_hidden_dim=128,\n",
    "    knowledge_dropout=0,\n",
    "    knowledge_dim=128,\n",
    "    knowledge_merge='self-attention',\n",
    "    text_encoder = 'roberta',\n",
    "    use_knowledge=True,\n",
    "    freeze_llm=True,\n",
    "    tune_llm_layer_norms=False,\n",
    "    freeze_meta_networks=False,\n",
    "    # dataset\n",
    "    batch_size=64,\n",
    "    min_num_context=3,\n",
    "    max_num_context=20,\n",
    "    x_sampler='random-uniform-25',\n",
    "    noise=0,\n",
    "    # reproducibility\n",
    "    seed=44,\n",
    "    dataset='temperatures',\n",
    "    knowledge_type='desc',\n",
    "    num_targets=50,\n",
    "    path='latent'\n",
    "    #xy_self_attention='dot',\n",
    ")\n",
    "config.device = \"cuda\"\n",
    "\n",
    "data_path = '../data/data_with_desc.csv'\n",
    "data = pd.read_csv(data_path, header=None)\n",
    "data = TempData(data=data , max_num_context=10, device=config.device)\n",
    "\n",
    "\n",
    "model = INP(config).to(config.device)\n",
    "print(model)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "loss_func = ELBOLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "\n",
    "iter_losses = []\n",
    "for iter in tqdm(range(100000)):\n",
    "\n",
    "    batch = data.generate_batch(batch_size=64, device=config.device, return_knowledge=config.use_knowledge)\n",
    "   \n",
    "    p_y_pred, q_z_context, q_z_target = model(batch.x_context, batch.y_context, batch.x_target, batch.y_target, batch.knowledge)\n",
    "    print(p_y_pred.batch_shape)\n",
    "    print(q_z_context.batch_shape)\n",
    "    print(q_z_target.batch_shape)\n",
    "    losses = loss_func(p_y_pred, q_z_context, q_z_target, batch.y_target)\n",
    "    loss = losses[\"loss\"]\n",
    "    print(loss.item())\n",
    "    print(losses[\"kl\"], losses[\"log_p\"])\n",
    "    iter_losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    if iter % 100 == 0 and iter > 0:\n",
    "        print(f\"iter {iter+1}: Avg. Loss = {sum(iter_losses[-100:])/100}\")\n",
    "        # print(f\"iter {iter+1}: Avg. Loss = {sum(old_losses[-1000:])/1000}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            n_val_batches = 128\n",
    "            val_batch_size = 96\n",
    "            for _ in range(n_val_batches):\n",
    "                batch = data.generate_batch(batch_size=val_batch_size, training=False, return_knowledge=config.use_knowledge, device=config.device)\n",
    "                model.training = False\n",
    "                p_y_pred, q_z_context, q_z_target = model(batch.x_context, batch.y_context, batch.x_target, batch.y_target, batch.knowledge)\n",
    "                loss_dict = loss_func(p_y_pred, q_z_context, q_z_target, batch.y_target)\n",
    "                val_loss += loss_dict[\"loss\"].item()\n",
    "            print(f\"iter {iter+1}: Val Loss: {val_loss / n_val_batches}\")\n",
    "        model.training = True\n",
    "        \n",
    "    if iter % 2000 == 0:\n",
    "        model.training = False\n",
    "        batch = data.generate_batch(batch_size=1, training=False, return_knowledge=config.use_knowledge, device=config.device)\n",
    "        plot_predictive(model, batch, save=False, iter=None)\n",
    "        model.training = True\n",
    "        # probs = outputs[0].probs\n",
    "        # predictions = torch.tensor(probs > 0.5, dtype=torch.float32)\n",
    "        # accuracy = (predictions == y_target).float().mean()\n",
    "    \n",
    "        # print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad0edb36-cd4a-4f30-87b9-780365842d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100000.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses)\n",
    "plt.ylim(bottom=0, top=0.1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b21e6c18-7ab4-4818-b90d-9e7a7bae3d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-8.0718e+00],\n",
      "          [-2.0211e+00],\n",
      "          [-2.7700e+01],\n",
      "          ...,\n",
      "          [-1.8111e+00],\n",
      "          [-5.7215e+02],\n",
      "          [-1.7846e+00]],\n",
      "\n",
      "         [[-8.7546e+00],\n",
      "          [-4.8846e-01],\n",
      "          [-1.2620e+00],\n",
      "          ...,\n",
      "          [-1.6435e+04],\n",
      "          [-2.8456e-01],\n",
      "          [-1.3199e+01]],\n",
      "\n",
      "         [[-1.4663e+00],\n",
      "          [-1.5914e+00],\n",
      "          [-1.1465e+00],\n",
      "          ...,\n",
      "          [-1.8884e+01],\n",
      "          [-1.5523e+00],\n",
      "          [-9.4274e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5821e+00],\n",
      "          [-3.7636e+00],\n",
      "          [-5.5700e+01],\n",
      "          ...,\n",
      "          [-4.4776e+01],\n",
      "          [-3.7308e+01],\n",
      "          [-1.5371e+00]],\n",
      "\n",
      "         [[ 5.4952e-01],\n",
      "          [-2.0759e+00],\n",
      "          [-7.5943e+00],\n",
      "          ...,\n",
      "          [-4.3264e+00],\n",
      "          [-2.9236e-01],\n",
      "          [-6.1717e+01]],\n",
      "\n",
      "         [[-1.6673e+00],\n",
      "          [-2.0342e+00],\n",
      "          [-1.1290e+00],\n",
      "          ...,\n",
      "          [-2.5668e+00],\n",
      "          [-1.4310e+00],\n",
      "          [-2.4188e+00]]]])\n",
      "torch.Size([1, 64, 288, 1])\n",
      "tensor([[-1.8002e+07, -3.6932e+05, -3.3784e+04, -9.8653e+03, -2.0240e+05,\n",
      "         -3.4787e+04, -4.1503e+04, -4.8302e+07, -1.0468e+07, -1.6142e+04,\n",
      "         -1.7028e+05, -1.7272e+05, -3.8270e+04, -2.6949e+05, -3.2626e+05,\n",
      "         -1.5800e+05, -4.7606e+04, -6.4736e+04, -1.5969e+05, -4.1177e+04,\n",
      "         -5.0579e+05, -5.2251e+04, -1.0110e+05, -2.4042e+04, -4.2402e+04,\n",
      "         -9.9430e+05, -6.7583e+04, -1.9779e+05, -7.3764e+03, -8.6469e+04,\n",
      "         -1.7889e+05, -9.6504e+04, -3.3274e+06, -4.7209e+04, -5.1703e+04,\n",
      "         -8.8144e+04, -2.2191e+05, -5.0459e+07, -7.3903e+04, -4.6864e+07,\n",
      "         -1.2500e+05, -1.3922e+05, -5.5218e+03, -1.4655e+05, -8.4701e+04,\n",
      "         -2.1350e+05, -1.2907e+05, -2.6854e+05, -8.3970e+03, -6.5292e+05,\n",
      "         -9.8059e+04, -4.4078e+04, -4.4682e+05, -8.8024e+04, -7.6136e+04,\n",
      "         -4.6327e+05, -1.2989e+04, -4.9420e+04, -1.5505e+05, -2.3353e+04,\n",
      "         -7.5790e+04, -1.1042e+05, -4.9395e+04, -1.2622e+06]])\n",
      "torch.Size([1, 64, 288, 1]) torch.Size([])\n",
      "tensor([[[-8.0718e+00, -2.0211e+00, -2.7700e+01,  ..., -1.8111e+00,\n",
      "          -5.7215e+02, -1.7846e+00],\n",
      "         [-8.7546e+00, -4.8846e-01, -1.2620e+00,  ..., -1.6435e+04,\n",
      "          -2.8456e-01, -1.3199e+01],\n",
      "         [-1.4663e+00, -1.5914e+00, -1.1465e+00,  ..., -1.8884e+01,\n",
      "          -1.5523e+00, -9.4274e-01],\n",
      "         ...,\n",
      "         [-1.5821e+00, -3.7636e+00, -5.5700e+01,  ..., -4.4776e+01,\n",
      "          -3.7308e+01, -1.5371e+00],\n",
      "         [ 5.4952e-01, -2.0759e+00, -7.5943e+00,  ..., -4.3264e+00,\n",
      "          -2.9236e-01, -6.1717e+01],\n",
      "         [-1.6673e+00, -2.0342e+00, -1.1290e+00,  ..., -2.5668e+00,\n",
      "          -1.4310e+00, -2.4188e+00]]])\n",
      "torch.Size([1, 64, 288])\n",
      "tensor([[-1.8002e+07, -3.6932e+05, -3.3784e+04, -9.8653e+03, -2.0240e+05,\n",
      "         -3.4787e+04, -4.1503e+04, -4.8302e+07, -1.0468e+07, -1.6142e+04,\n",
      "         -1.7028e+05, -1.7272e+05, -3.8270e+04, -2.6949e+05, -3.2626e+05,\n",
      "         -1.5800e+05, -4.7606e+04, -6.4736e+04, -1.5969e+05, -4.1177e+04,\n",
      "         -5.0579e+05, -5.2251e+04, -1.0110e+05, -2.4042e+04, -4.2402e+04,\n",
      "         -9.9430e+05, -6.7583e+04, -1.9779e+05, -7.3764e+03, -8.6469e+04,\n",
      "         -1.7889e+05, -9.6504e+04, -3.3274e+06, -4.7209e+04, -5.1703e+04,\n",
      "         -8.8144e+04, -2.2191e+05, -5.0459e+07, -7.3903e+04, -4.6864e+07,\n",
      "         -1.2500e+05, -1.3922e+05, -5.5218e+03, -1.4655e+05, -8.4701e+04,\n",
      "         -2.1350e+05, -1.2907e+05, -2.6854e+05, -8.3970e+03, -6.5292e+05,\n",
      "         -9.8059e+04, -4.4078e+04, -4.4682e+05, -8.8024e+04, -7.6136e+04,\n",
      "         -4.6327e+05, -1.2989e+04, -4.9420e+04, -1.5505e+05, -2.3353e+04,\n",
      "         -7.5790e+04, -1.1042e+05, -4.9395e+04, -1.2622e+06]])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64, 288]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.independent import Independent\n",
    "\n",
    "loc = torch.randn(1, 64, 288, 1)\n",
    "scale = torch.abs(torch.randn(1, 64, 288, 1))\n",
    "\n",
    "# mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))\n",
    "normal = Normal(loc, scale)\n",
    "diagn = Independent(Normal(loc, scale), 1)\n",
    "\n",
    "target = torch.randn(64, 288, 1)\n",
    "# print(mvn.batch_shape, mvn.event_shape)\n",
    "# print(mvn.log_prob(target))\n",
    "print(normal.log_prob(target))\n",
    "print(normal.log_prob(target).shape)\n",
    "print(normal.log_prob(target).sum(dim=(-1, -2)))\n",
    "print(normal.batch_shape, normal.event_shape)\n",
    "\n",
    "print(diagn.log_prob(target))\n",
    "print(diagn.log_prob(target).shape)\n",
    "print(diagn.log_prob(target).sum(dim=-1))\n",
    "print(diagn.log_prob(target).sum(dim=-1).shape)\n",
    "print(diagn.batch_shape, diagn.event_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
